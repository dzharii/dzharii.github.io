"use strict";(self.webpackChunkzharii=self.webpackChunkzharii||[]).push([[6291],{3905:function(e,a,t){t.d(a,{Zo:function(){return c},kt:function(){return u}});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function p(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?p(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):p(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},p=Object.keys(e);for(n=0;n<p.length;n++)t=p[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var p=Object.getOwnPropertySymbols(e);for(n=0;n<p.length;n++)t=p[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=n.createContext({}),l=function(e){var a=n.useContext(i),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},c=function(e){var a=l(e.components);return n.createElement(i.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},k=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,p=e.originalType,i=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),k=l(t),u=r,h=k["".concat(i,".").concat(u)]||k[u]||m[u]||p;return t?n.createElement(h,o(o({ref:a},c),{},{components:t})):n.createElement(h,o({ref:a},c))}));function u(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var p=t.length,o=new Array(p);o[0]=k;var s={};for(var i in a)hasOwnProperty.call(a,i)&&(s[i]=a[i]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var l=2;l<p;l++)o[l]=t[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}k.displayName="MDXCreateElement"},38906:function(e,a,t){t.r(a),t.d(a,{frontMatter:function(){return s},contentTitle:function(){return i},metadata:function(){return l},toc:function(){return c},default:function(){return k}});var n=t(87462),r=t(63366),p=(t(67294),t(3905)),o=["components"],s={},i=void 0,l={unversionedId:"dev-scala-spark-synapse-bigdata",id:"dev-scala-spark-synapse-bigdata",title:"dev-scala-spark-synapse-bigdata",description:"Dev Scala, Apache Spark & Big Data",source:"@site/docs/dev-scala-spark-synapse-bigdata.md",sourceDirName:".",slug:"/dev-scala-spark-synapse-bigdata",permalink:"/docs/dev-scala-spark-synapse-bigdata",editUrl:"https://github.com/dzharii/dzharii.github.io/docs/dev-scala-spark-synapse-bigdata.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"dev-retro-8bit",permalink:"/docs/dev-retro-8bit"},next:{title:"dev-stable-diffusion-cpu",permalink:"/docs/dev-stable-diffusion-cpu"}},c=[{value:"Dev Scala, Apache Spark &amp; Big Data",id:"dev-scala-apache-spark--big-data",children:[],level:2},{value:"Spark",id:"spark",children:[{value:"Java Docs",id:"java-docs",children:[],level:3},{value:"Examples",id:"examples",children:[],level:3},{value:"Links",id:"links",children:[],level:3},{value:"Videos",id:"videos",children:[],level:3}],level:2},{value:"Azure Synapse Analytics",id:"azure-synapse-analytics",children:[],level:2},{value:"Overview",id:"overview",children:[],level:2},{value:"Where the things are:",id:"where-the-things-are",children:[],level:2},{value:"Samples",id:"samples",children:[],level:2},{value:"Azure Data Lake Storage Gen 2",id:"azure-data-lake-storage-gen-2",children:[],level:2},{value:"Azure Data Lake URIs",id:"azure-data-lake-uris",children:[],level:2},{value:"Spark Notes",id:"spark-notes",children:[],level:2},{value:"Parquet",id:"parquet",children:[],level:2}],m={toc:c};function k(e){var a=e.components,s=(0,r.Z)(e,o);return(0,p.kt)("wrapper",(0,n.Z)({},m,s,{components:a,mdxType:"MDXLayout"}),(0,p.kt)("h2",{id:"dev-scala-apache-spark--big-data"},"Dev Scala, Apache Spark & Big Data"),(0,p.kt)("p",null,"[","[",(0,p.kt)("em",{parentName:"p"},"TOC"),"]","]"),(0,p.kt)("h2",{id:"spark"},"Spark"),(0,p.kt)("p",null,"2023-02-07 ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/"},"Overview - Spark 3.3.1 Documentation")," ",(0,p.kt)("inlineCode",{parentName:"p"},"https://spark.apache.org/docs/latest/")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Spark Latest Official  Documentation site\nApache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/sql-programming-guide.html"},"Spark SQL")," for SQL and structured data processing, ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html"},"pandas API on Spark")," for pandas workloads, ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/ml-guide.html"},"MLlib")," for machine learning, ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/graphx-programming-guide.html"},"GraphX")," for graph processing, and ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html"},"Structured Streaming")," for incremental computation and stream processing.")),(0,p.kt)("p",null,(0,p.kt)("strong",{parentName:"p"},"Programming Guides:")),(0,p.kt)("ul",null,(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/quick-start.html"},"Quick Start"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"\ud83c\udf87 ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/rdd-programming-guide.html"},"RDDs, Accumulators, Broadcasts Vars"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"\ud83c\udf87 ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/sql-programming-guide.html"},"SQL, DataFrames, and Datasets"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/structured-streaming-programming-guide.html"},"Structured Streaming"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"\ud83c\udf87 ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/streaming-programming-guide.html"},"Spark Streaming (DStreams)"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/ml-guide.html"},"MLlib (Machine Learning)"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/graphx-programming-guide.html"},"GraphX (Graph Processing)"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/sparkr.html"},"SparkR (R on Spark)"))),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/3.3.1/api/python/getting_started/index.html"},"PySpark (Python on Spark)")))),(0,p.kt)("p",null,"2023-01-26 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/apache/spark/"},"GitHub - apache/spark: Apache Spark - A unified analytics engine for large-scale data processing")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Apache Spark Github Repository")),(0,p.kt)("p",null,"2023-01-26 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/awesome-spark/awesome-spark"},"GitHub - awesome-spark/awesome-spark"),"  "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"A curated list of awesome Apache Spark packages and resources.")),(0,p.kt)("p",null,"2023-01-26 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/dotnet/spark"},"GitHub - dotnet/spark")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"}," .NET for Apache Spark makes Apache Spark easily accessible to .NET developers.")),(0,p.kt)("p",null,"2023-05-03 ",(0,p.kt)("a",{parentName:"p",href:"https://api-docs.databricks.com/scala/spark/latest/org/apache/spark/sql/Dataset.html"},"Databricks Scala Spark API - org.apache.spark.sql.Dataset")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230502225512421",src:t(67070).Z,width:"1080",height:"549"}))),(0,p.kt)("h3",{id:"java-docs"},"Java Docs"),(0,p.kt)("ul",null,(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/api/java/index.html"},"Spark Java API Docs Class Reference")),(0,p.kt)("blockquote",{parentName:"li"},(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230207152752477",src:t(62615).Z,width:"869",height:"364"}))))),(0,p.kt)("h3",{id:"examples"},"Examples"),(0,p.kt)("p",null,"2017 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/trK54Ylmz/kafka-spark-streaming-example"},"trK54Ylmz/kafka-spark-streaming-example: Simple examle for Spark Streaming over Kafka topic")," Github"),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"}," A bit old sample for Spark streaming, but it has some good bash/command line examples")),(0,p.kt)("p",null,"2020 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/nitinware/spark-starter"},"nitinware/spark-starter: spark starter java project")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Spark Java Maven Simple starter project")),(0,p.kt)("h3",{id:"links"},"Links"),(0,p.kt)("p",null,"2023-03-13 ",(0,p.kt)("a",{parentName:"p",href:"https://www.infoq.com/presentations/abstract-algebra-analytics/"},"Add ALL the Things: Abstract Algebra Meets Analytics")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"2013-03-07 ",(0,p.kt)("a",{parentName:"p",href:"https://web.archive.org/web/20130307235411/http://blog.aggregateknowledge.com/"},"AK Tech Blog"),"\n2023-03-14 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/avibryant/simmer"},"GitHub - avibryant/simmer: Reduce your data. A unix filter for algebird-powered aggregation."),"\n2023-03-14 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/twitter/algebird"},"GitHub - twitter/algebird: Abstract Algebra for Scala"))),(0,p.kt)("p",null,"2023-03-13 ",(0,p.kt)("a",{parentName:"p",href:"https://app.pluralsight.com/course-player?clipId=da79701c-5b62-4649-a366-686c471f0934"},"Apache Spark Fundamentals | Pluralsight")),(0,p.kt)("p",null,"2023-02-12 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/awesome-spark/awesome-spark"},"awesome-spark/awesome-spark: A curated list of awesome Apache Spark packages and resources.")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230212113428859",src:t(73924).Z,width:"789",height:"278"}))),(0,p.kt)("h3",{id:"videos"},"Videos"),(0,p.kt)("p",null,"2023-02-12 \ud83c\udfa5 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=daXEp4HmS-E"},"Apache Spark Core\u2014Deep Dive\u2014Proper Optimization Daniel Tomes Databricks - YouTube")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"21:14:\n",(0,p.kt)("img",{alt:"image-20230212015142337",src:t(53486).Z,width:"1262",height:"659"})),(0,p.kt)("ul",{parentName:"blockquote"},(0,p.kt)("li",{parentName:"ul"},"2023-02-12 \ud83c\udfa5 ",(0,p.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=_ArCesElWp8"},"Apache Spark Core \u2013 Practical Optimization Daniel Tomes Databricks - YouTube")),(0,p.kt)("li",{parentName:"ul"},"See Slides at: ",(0,p.kt)("a",{parentName:"li",href:"https://blog.zharii.com/docs/resources/2023-02-12-Slides--Apache-Spark-Core-Deep-Dive-Proper-Optimization"},"2023-02-12 Apache Spark Core\u2014Deep Dive\u2014Proper Optimization Daniel Tomes Databricks")))),(0,p.kt)("p",null,"2023-02-12 ",(0,p.kt)("a",{parentName:"p",href:"https://sparkbyexamples.com/spark/spark-shuffle-partitions/"},"Spark SQL Shuffle Partitions - Spark By {Examples}")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230212091729215",src:t(71715).Z,width:"1148",height:"548"}))),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre"},"spark.sql.shuffle.partitions\n")),(0,p.kt)("h2",{id:"azure-synapse-analytics"},"Azure Synapse Analytics"),(0,p.kt)("h2",{id:"overview"},"Overview"),(0,p.kt)("p",null,"Azure Synapse is a big data analytics service provided by Microsoft that integrates big data and data warehousing into a single platform. It allows organizations to analyze large amounts of data from various sources including structured, semi-structured and unstructured data."),(0,p.kt)("p",null,"People use Azure Synapse for tasks such as data warehousing, data lake storage, big data analytics, and machine learning."),(0,p.kt)("p",null,"Main features of Azure Synapse include:"),(0,p.kt)("ul",null,(0,p.kt)("li",{parentName:"ul"},"Seamless integration of big data and data warehousing"),(0,p.kt)("li",{parentName:"ul"},"Serverless big data analytics through Spark"),(0,p.kt)("li",{parentName:"ul"},"Advanced security and data protection"),(0,p.kt)("li",{parentName:"ul"},"Hybrid data management and analytics"),(0,p.kt)("li",{parentName:"ul"},"Automated data ingestion and data preparation"),(0,p.kt)("li",{parentName:"ul"},"Advanced data visualization and exploration tools.")),(0,p.kt)("p",null,(0,p.kt)("img",{alt:"image-20230207112125757",src:t(61531).Z,width:"981",height:"547"})),(0,p.kt)("h2",{id:"where-the-things-are"},"Where the things are:"),(0,p.kt)("ul",null,(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Home")," -- No place like it!"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Data")," -- Manage / Create internal Hadoop / Spark tables"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Develop")," -- Upload Spark Jobs, create, import, export and run Notebooks (Python, C#, SQL, Scala)"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Integrate")," -- Create data ingestion / data processing pipelines with visual editor"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Monitor")," --  Spark Logs and Metrics"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("strong",{parentName:"li"},"Manage")," -- Create Spark Pools, manage resources, create linked resources (link external resources like Cosmos DB, SQL Server, Blob Containers etc.)")),(0,p.kt)("h2",{id:"samples"},"Samples"),(0,p.kt)("p",null,"2023-02-07 \ud83d\udc96 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/Azure-Samples/Synapse"},(0,p.kt)("inlineCode",{parentName:"a"},"Azure-Samples/Synapse: Samples for Azure Synapse Analytics"))," GitHub"),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("strong",{parentName:"p"},"MSFT"),": This is a very comprehensive repository with tons of Notebooks and Spark Jobs samples. The best place to start.\n",(0,p.kt)("strong",{parentName:"p"},"Contents")),(0,p.kt)("ul",{parentName:"blockquote"},(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/CLI"},"CLI")," - Azure CLI"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/Data"},"Data")," - Small sample data sets"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/PowerShell"},"PowerShell")," - Azure PowerShell scripts"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/Notebooks"},"Notebooks")," - Notebook files"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/Spark"},"Spark")," - Code for using Apache Spark"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://github.com/Azure-Samples/Synapse/tree/master/SQL"},"SQL")," - T-SQL scripts"))),(0,p.kt)("p",null,"2023-02-07 \ud83d\udc96 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/microsoft/SynapseML"},"microsoft/SynapseML: Simple and Distributed Machine Learning")," Github"),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("strong",{parentName:"p"},"MSFT"),": Synapse Machine Learning specific repository."),(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230207121611495",src:t(63347).Z,width:"503",height:"456"}))),(0,p.kt)("p",null,"2023-02-07 ",(0,p.kt)("strong",{parentName:"p"},"Azure Synapse Analytics Workshop")," (level 400, 4 days) ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/solliancenet/azure-synapse-analytics-workshop-400"},"solliancenet/azure-synapse-analytics-workshop-400")," Github, Slides"),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"External. Workshop Slides and materials\n",(0,p.kt)("img",{alt:"image-20230207132348919",src:t(73446).Z,width:"778",height:"246"}))),(0,p.kt)("p",null,"2023-02-07 \ud83d\udc96 ",(0,p.kt)("strong",{parentName:"p"},"Azure Analytics End to End with Azure Synapse - Deployment Accelerator")," ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/Azure/azure-synapse-analytics-end2end"},"Azure/azure-synapse-analytics-end2end")," Github "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Slides and diagrams and ",(0,p.kt)("strong",{parentName:"p"},"Bicep / ARM Templates"),"  for an End to End Solution sample"),(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230207132650444",src:t(61230).Z,width:"805",height:"567"}))),(0,p.kt)("p",null,"2023-02-07 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/microsoft/AzureSynapseEndToEndDemo"},"microsoft/AzureSynapseEndToEndDemo")," Github"),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"This repository provides one-click infrastructure and artifact deployment for Azure Synapse Analytics to get you started with Big Data Analytics on a large sized Health Care sample data. You will learn how to ingest, process and serve large volumes of data using various components of Synapse.")),(0,p.kt)("p",null,"2023-04-09 ",(0,p.kt)("a",{parentName:"p",href:"https://dustinvannoy.com/2021/02/03/azure-synapse-spark-with-scala/"},"Azure Synapse Spark with Scala | DUSTIN VANNOY")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230413184249520",src:t(75872).Z,width:"1188",height:"745"}))),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-scala"},'val inputDF = spark.read.parquet(yellowSourcePath)\n\n// Take your pick on how to transform, withColumn or SQL Expressions. Only one of these is needed.\n\n// Option A\n// val transformedDF = {\n//     inputDF\n//      .withColumn("yearMonth", regexp_replace(substring("tpepPickupDatetime",1,7), \'-\', \'_\'))\n//      .withColumn("pickupDt", to_date("tpepPickupDatetime", dateFormat)) \n//      .withColumn("dropoffDt", to_date("tpepDropoffDatetime", dateFormat))\n//      .withColumn("tipPct", col("tipAmount") / col("totalAmount"))\n// }\n\n// Option B\nval transformedDF = inputDF.selectExpr(\n                  "*",\n                  "replace(left(tpepPickupDatetime, 7),\'-\',\'_\') as yearMonth",\n                  s"to_date(tpepPickupDatetime, \'$dateFormat\') as pickupDt",\n                  s"to_date(tpepDropoffDatetime, \'$dateFormat\') as dropoffDt",\n                  "tipAmount/totalAmount as tipPct")\n\nval zoneDF = spark.read.format("delta").load(taxiZonePath)\n\n// Join to bring in Taxi Zone data\nval tripDF = {\n    transformedDF.as("t")\n        .join(zoneDF.as("z"), expr("t.PULocationID == z.LocationID"), joinType="left").drop("LocationID")\n        .withColumnRenamed("Burough", "PickupBurrough")\n        .withColumnRenamed("Zone", "PickupZone")\n        .withColumnRenamed("ServiceZone", "PickupServiceZone")\n}\n\ntripDF.write.mode("overwrite").partitionBy("yearMonth").format("delta").save(yellowDeltaPath)\n')),(0,p.kt)("h2",{id:"azure-data-lake-storage-gen-2"},"Azure Data Lake Storage Gen 2"),(0,p.kt)("p",null,"2023-02-03 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=NHn5GAkvlwg"},"Azure Data Lake Storage Gen 2 Overview - YouTube")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"}," ",(0,p.kt)("img",{alt:"image-20230207155303993",src:t(58529).Z,width:"661",height:"343"}))),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"}," Gen2 is build on top of Storage Account with this option enabled (Enable hierarchical namespace):"),(0,p.kt)("p",{parentName:"blockquote"}," ",(0,p.kt)("img",{alt:"image-20230207155458865",src:t(57751).Z,width:"483",height:"485"})),(0,p.kt)("p",{parentName:"blockquote"}," HNS enables real folder structure in blob storage containers. ")),(0,p.kt)("h2",{id:"azure-data-lake-uris"},"Azure Data Lake URIs"),(0,p.kt)("ul",null,(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("inlineCode",{parentName:"li"},"wasbs://")," is Windows Azure Storage Blob (WASB) + S (Secure) example: ",(0,p.kt)("inlineCode",{parentName:"li"},"wasbs://8f871c14-f903-42a8-9011-7d6fb48896af@cl3p8zpng3juv1ahtsv6cpl2.blob.core.windows.net/events/...")," used as URI in Hadoop / Yarn / Spark"),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("inlineCode",{parentName:"li"},"abfss://")," stands for Azure Blob File System + S (Secure) and Microsoft recommends it for big data workloads as it is optimized for it. Sample: ",(0,p.kt)("inlineCode",{parentName:"li"},"abfss://myfstest@datalakestorealpha.dfs.core.windows.net/synapse/workspaces/20230203workspace/..."))),(0,p.kt)("h1",{id:"scala-and-spark"},"Scala and Spark"),(0,p.kt)("p",null,"2023-02-26 \ud83d\udd25 ",(0,p.kt)("a",{parentName:"p",href:"https://docs.scala-lang.org/cheatsheets/index.html"},"Scala Cheatsheet Scala Documentation")),(0,p.kt)("p",null,(0,p.kt)("img",{alt:"image-20230413165412480",src:t(4608).Z,width:"1188",height:"373"})),(0,p.kt)("p",null,"2023-04-11 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=-xRfJcwhy7A"},"#Scala Crash Course by a Scala Veteran (with some JavaScript flavor) - YouTube")),(0,p.kt)("p",null,"2023-04-10 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=DzFt0YkZo8M"},"Scala Tutorial - YouTube")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Derek Banas Cheatsheet:\n2023-04-10 ",(0,p.kt)("a",{parentName:"p",href:"https://www.newthinktank.com/2015/08/learn-scala-one-video/"},"Learn Scala in One Video")," ")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"Scala Syntax cheat sheet"),(0,p.kt)("pre",{parentName:"blockquote"},(0,p.kt)("code",{parentName:"pre",className:"language-scala"},'// Shorthand notation (No randInt++, or randInt--)\nrandInt += 1\n"randInt += 1" + randInt\n'))),(0,p.kt)("p",null,"2023-04-10 ",(0,p.kt)("a",{parentName:"p",href:"https://docs.scala-lang.org/getting-started/index.html#using-the-scala-installer-recommended-way"},"Getting Started | Scala Documentation")),(0,p.kt)("pre",null,(0,p.kt)("code",{parentName:"pre",className:"language-cs"},"cs install scala:2.11.12 && cs install scalac:2.11.12\n")),(0,p.kt)("p",null,"2023-04-03 ",(0,p.kt)("a",{parentName:"p",href:"https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-SparkSession-implicits.html"},"implicits Object\u2009\u2014\u2009Implicits Conversions \xb7 The Internals of Spark SQL")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"The Internals of Spark SQL (Apache Spark 2.4.5)"),(0,p.kt)("p",{parentName:"blockquote"},"Welcome to ",(0,p.kt)("strong",{parentName:"p"},"The Internals of Spark SQL")," online book!"),(0,p.kt)("p",{parentName:"blockquote"},"I\u2019m ",(0,p.kt)("a",{parentName:"p",href:"https://pl.linkedin.com/in/jaceklaskowski"},"Jacek Laskowski"),", a freelance IT consultant, software engineer and technical instructor specializing in ",(0,p.kt)("a",{parentName:"p",href:"https://spark.apache.org/"},"Apache Spark"),", ",(0,p.kt)("a",{parentName:"p",href:"https://kafka.apache.org/"},"Apache Kafka"),", ",(0,p.kt)("a",{parentName:"p",href:"https://delta.io/"},"Delta Lake")," and ",(0,p.kt)("a",{parentName:"p",href:"https://kafka.apache.org/documentation/streams/"},"Kafka Streams")," (with ",(0,p.kt)("a",{parentName:"p",href:"https://www.scala-lang.org/"},"Scala")," and ",(0,p.kt)("a",{parentName:"p",href:"https://www.scala-sbt.org/"},"sbt"),").")),(0,p.kt)("p",null,"2023-04-03 ",(0,p.kt)("a",{parentName:"p",href:"https://books.japila.pl/apache-spark-internals/"},"The Internals of Apache Spark")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230413170904189",src:t(77173).Z,width:"1225",height:"670"}))),(0,p.kt)("h2",{id:"spark-notes"},"Spark Notes"),(0,p.kt)("p",null,(0,p.kt)("img",{alt:"image-20230413165557540",src:t(77539).Z,width:"947",height:"511"})),(0,p.kt)("p",null,(0,p.kt)("img",{alt:"image-20230413165610679",src:t(2681).Z,width:"803",height:"392"})),(0,p.kt)("p",null,(0,p.kt)("img",{alt:"image-20230413165631535",src:t(40882).Z,width:"740",height:"380"})),(0,p.kt)("p",null,"2023-02-12 ",(0,p.kt)("a",{parentName:"p",href:"https://sparkbyexamples.com/spark/spark-shuffle-partitions/"},"Spark SQL Shuffle Partitions - Spark By {Examples}")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"In this Apache Spark Tutorial, you will learn Spark with Scala code examples and every sample example explained here is available at ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/spark-examples"},"Spark Examples Github Project")," for reference. All Spark examples provided in this Apache Spark Tutorial are basic, simple, and easy to practice for beginners who are enthusiastic to learn Spark, and these sample examples were tested in our development environment.")),(0,p.kt)("p",null,"2023-02-12 ",(0,p.kt)("a",{parentName:"p",href:"https://antonz.org/sql-window-functions-ranking/"},"SQL Window Functions: Ranking")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("em",{parentName:"p"},"This is an excerpt from my book ",(0,p.kt)("a",{parentName:"em",href:"https://antonz.org/sql-window-functions-book"},"SQL Window Functions Explained"),". The book is a clear and visual introduction to the topic with lots of practical exercises.")),(0,p.kt)("p",{parentName:"blockquote"},"Ranking means coming up with all kinds of ratings, starting from the winners of the World Swimming Championships and ending with the Forbes 500."),(0,p.kt)("p",{parentName:"blockquote"},"We will rank records from the toy ",(0,p.kt)("inlineCode",{parentName:"p"},"employees")," table:"),(0,p.kt)("pre",{parentName:"blockquote"},(0,p.kt)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id \u2502 name  \u2502  city  \u2502 department \u2502 salary \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 11 \u2502 Diane \u2502 London \u2502 hr         \u2502 70     \u2502\n\u2502 12 \u2502 Bob   \u2502 London \u2502 hr         \u2502 78     \u2502\n\u2502 21 \u2502 Emma  \u2502 London \u2502 it         \u2502 84     \u2502\n\u2502 22 \u2502 Grace \u2502 Berlin \u2502 it         \u2502 90     \u2502\n\u2502 23 \u2502 Henry \u2502 London \u2502 it         \u2502 104    \u2502\n\u2502 24 \u2502 Irene \u2502 Berlin \u2502 it         \u2502 104    \u2502\n\u2502 25 \u2502 Frank \u2502 Berlin \u2502 it         \u2502 120    \u2502\n\u2502 31 \u2502 Cindy \u2502 Berlin \u2502 sales      \u2502 96     \u2502\n\u2502 32 \u2502 Dave  \u2502 London \u2502 sales      \u2502 96     \u2502\n\u2502 33 \u2502 Alice \u2502 Berlin \u2502 sales      \u2502 100    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("a",{parentName:"p",href:"https://sqlime.org/#employees.db"},"playground")," \u2022 ",(0,p.kt)("a",{parentName:"p",href:"https://antonz.org/sql-window-functions-book/employees.sql"},"download")),(0,p.kt)("p",{parentName:"blockquote"},"Table of contents:"),(0,p.kt)("ul",{parentName:"blockquote"},(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#salary-rating"},"Salary rating")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#window-ordering-vs-result-ordering"},"Window ordering vs. result ordering")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#sorting-uniqueness"},"Sorting uniqueness")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#salary-rating-by-department"},"Salary rating by department")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#salary-groups"},"Salary groups")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#ranking-functions"},"Ranking functions")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("a",{parentName:"li",href:"https://antonz.org/sql-window-functions-ranking/#keep-it-up"},"Keep it up")))),(0,p.kt)("p",null,"2023-02-12 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=daXEp4HmS-E"},"Apache Spark Core\u2014Deep Dive\u2014Proper Optimization Daniel Tomes Databricks - YouTube")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},'Optimizing spark jobs through a true understanding of spark core. Learn: What is a partition? What is the difference between read/shuffle/write partitions? How to increase parallelism and decrease output files? Where does shuffle data go between stages? What is the "right" size for your spark partitions and files? Why does a job slow down with only a few tasks left and never finish? Why doesn\'t adding nodes decrease my compute time?'),(0,p.kt)("p",{parentName:"blockquote"},(0,p.kt)("img",{alt:"image-20230212142755335",src:t(6968).Z,width:"1297",height:"733"}))),(0,p.kt)("p",null,"2023-02-11 ",(0,p.kt)("a",{parentName:"p",href:"https://lilianweng.github.io/posts/2021-09-25-train-large/"},"How to Train Really Large Models on Many GPUs? Lil'Log")," "),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"},"In recent years, we are seeing better results on many NLP benchmark tasks with larger pre-trained ",(0,p.kt)("a",{parentName:"p",href:"https://lilianweng.github.io/posts/2019-01-31-lm/"},"language models"),". How to train large and deep neural networks is challenging, as it demands a large amount of GPU memory and a long horizon of training time."),(0,p.kt)("p",{parentName:"blockquote"},"However an individual GPU worker has limited memory and the sizes of many large models have grown beyond a single GPU. There are several parallelism paradigms to enable model training across multiple GPUs, as well as a variety of model architecture and memory saving designs to help make it possible to train ",(0,p.kt)("em",{parentName:"p"},"very large")," neural networks.")),(0,p.kt)("p",null,"2023-01-25 ",(0,p.kt)("a",{parentName:"p",href:"https://vincentlauzon.com/2018/06/05/event-hubs-ingestion-performance-and-throughput/"},"Event Hubs ingestion performance and throughput Vincent-Philippe Lauzon\u2019s")),(0,p.kt)("blockquote",null,(0,p.kt)("p",{parentName:"blockquote"}," Here are some recommendations in the light of the performance and throughput results:"),(0,p.kt)("ul",{parentName:"blockquote"},(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If we send ",(0,p.kt)("strong",{parentName:"p"},"many events"),": always reuse connections, i.e. do not create a connection only for one event. This is valid for both AMQP and HTTP. A simple ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/vplauzon/streaming/blob/master/ClientPerf/ClientConsole/EventHubClientPool.cs"},"Connection Pool pattern")," makes this easy.")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If we send ",(0,p.kt)("strong",{parentName:"p"},"many events")," & ",(0,p.kt)("strong",{parentName:"p"},"throughput")," is a concern: use AMQP.")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If we send ",(0,p.kt)("strong",{parentName:"p"},"few events")," and ",(0,p.kt)("strong",{parentName:"p"},"latency")," is a concern: use HTTP / REST.")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If events naturally comes in ",(0,p.kt)("strong",{parentName:"p"},"batch of many events"),": use batch API.")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If events ",(0,p.kt)("strong",{parentName:"p"},"do not")," naturally comes in ",(0,p.kt)("strong",{parentName:"p"},"batch of many events"),": simply stream events. ",(0,p.kt)("strong",{parentName:"p"},"Do not try")," to batch them unless network IO is constrained.")),(0,p.kt)("li",{parentName:"ul"},(0,p.kt)("p",{parentName:"li"},"If a ",(0,p.kt)("strong",{parentName:"p"},"latency")," of ",(0,p.kt)("strong",{parentName:"p"},"0.1 seconds")," is a concern: move the call to Event Hubs away from your critical performance path."),(0,p.kt)("p",{parentName:"li"},"Let\u2019s now look at the tests we did to come up with those recommendations.")))),(0,p.kt)("p",null,"2023-02-16 ",(0,p.kt)("a",{parentName:"p",href:"https://www.scala-js.org/doc/sjs-for-js/es6-to-scala-part1.html"},"From ES6 to Scala: Basics - Scala.js")),(0,p.kt)("p",null,"2023-02-15 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/alexandru/scala-best-practices"},"GitHub - alexandru/scala-best-practices: A collection of Scala best practices")),(0,p.kt)("p",null,"2023-02-15 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/lauris/awesome-scala"},"lauris/awesome-scala: A community driven list of useful Scala libraries, frameworks and software.")),(0,p.kt)("p",null,"2023-02-15 ",(0,p.kt)("a",{parentName:"p",href:"https://scalacenter.github.io/scalafix/"},"Scalafix \xb7 Refactoring and linting tool for Scala")),(0,p.kt)("p",null,"2023-02-14 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/zouzias/spark-hello-world"},"zouzias/spark-hello-world: A simple hello world using Apache Spark")),(0,p.kt)("p",null,"2023-02-14 ",(0,p.kt)("a",{parentName:"p",href:"https://www.scala-sbt.org/1.x/docs/Installing-sbt-on-Windows.html"},"sbt Reference Manual \u2014 Installing sbt on Windows")),(0,p.kt)("p",null,"2023-02-14 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/lolski/sbt-cheatsheet"},"lolski/sbt-cheatsheet: Simple, no-nonsense guide to getting your Scala project up and running")),(0,p.kt)("p",null,"2023-02-14 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/marconilanna/scala-boilerplate"},"marconilanna/scala-boilerplate: Starting point for Scala projects")),(0,p.kt)("p",null,"2023-02-13 ",(0,p.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-performance-hyperspace?pivots=programming-language-scala"},"Hyperspace indexes for Apache Spark - Azure Synapse Analytics Microsoft Learn")),(0,p.kt)("p",null,"2023-02-13 ",(0,p.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=FjsnVueXijQ"},"The Azure Spark Showdown - Databricks VS Synapse Analytics - Simon Whiteley - YouTube")),(0,p.kt)("p",null,"2023-02-06 ",(0,p.kt)("a",{parentName:"p",href:"https://github.com/ossu/computer-science"},"ossu/computer-science: Path to a free self-taught education in Computer Science!")),(0,p.kt)("h2",{id:"parquet"},"Parquet"),(0,p.kt)("p",null,"2023-04-04 ",(0,p.kt)("a",{parentName:"p",href:"https://csvbase.com/blog/3"},'Parquet: more than just "Turbo CSV"')))}k.isMDXComponent=!0},61531:function(e,a,t){a.Z=t.p+"assets/images/image-20230207112125757-a8974a0dd3ffc023bcd3f8b94d3f99bc.png"},63347:function(e,a,t){a.Z=t.p+"assets/images/image-20230207121611495-3f69c4decf8d5ce9a5c73714ace78b3d.png"},73446:function(e,a,t){a.Z=t.p+"assets/images/image-20230207132348919-75d391f8878c07a4e036ab8cc29d001a.png"},61230:function(e,a,t){a.Z=t.p+"assets/images/image-20230207132650444-c4faf42680d1fde9899ec22204062b2b.png"},62615:function(e,a,t){a.Z=t.p+"assets/images/image-20230207152752477-82ace1f683460f437ad81c4946581495.png"},58529:function(e,a,t){a.Z=t.p+"assets/images/image-20230207155303993-57511d62444228513529c06cc627c8ed.png"},57751:function(e,a,t){a.Z=t.p+"assets/images/image-20230207155458865-18f778ae508d34fde62aed35db68f6c0.png"},6968:function(e,a,t){a.Z=t.p+"assets/images/image-20230212142755335-a32540c316f2ec75322c2205f2611499.png"},4608:function(e,a,t){a.Z=t.p+"assets/images/image-20230413165412480-74eed0eda8e8c178eb404b224dfcb390.png"},77539:function(e,a,t){a.Z=t.p+"assets/images/image-20230413165557540-9664b9a7ac4dd95efafb907560578ad8.png"},2681:function(e,a,t){a.Z=t.p+"assets/images/image-20230413165610679-dc44c48d33d4b09fd895342b9edce963.png"},40882:function(e,a,t){a.Z=t.p+"assets/images/image-20230413165631535-dc68b721d6d92bfdf4a5412c4fdbffbd.png"},77173:function(e,a,t){a.Z=t.p+"assets/images/image-20230413170904189-9bf512e3d46424ad86f40e351bfdbd34.png"},75872:function(e,a,t){a.Z=t.p+"assets/images/image-20230413184249520-7fe1ac0631902f5ad3a50cb7021ac02c.png"},67070:function(e,a,t){a.Z=t.p+"assets/images/image-20230502225512421-ebf1589b4b7bd54c432ca5d5fe7dd440.png"},53486:function(e,a,t){a.Z=t.p+"assets/images/image-20230212015142337-f9fbd5a482899edf13fccc7ccad8c23e.png"},71715:function(e,a,t){a.Z=t.p+"assets/images/image-20230212091729215-2446d1b72f50218dd76d49bed5df9ab1.png"},73924:function(e,a,t){a.Z=t.p+"assets/images/image-20230212113428859-9e8bcfc7eb854e4ad04afd69761db00c.png"}}]);